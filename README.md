# Distributed Reinforcement Learning Algorithms ğŸ¤–

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

A collection of PyTorch implementations of distributed reinforcement learning algorithms, designed with clarity and educational value in mind.

## ğŸš€ Features

- **Clear, documented implementations** of state-of-the-art distributed RL algorithms
- **Educational focus** with detailed comments and explanations
- **Modular design** for easy extension and modification
- **Comprehensive logging** with Weights & Biases integration
- **Configurable experiments** using Hydra

## ğŸ“¦ Currently Implemented

### Asynchronous DQN (A3C-DQN variant)
An implementation based on ["Asynchronous Methods for Deep Reinforcement Learning"](https://arxiv.org/abs/1602.01783) (Mnih et al., 2016).

**Key Features:**
- âœ¨ Parallel training across multiple workers
- ğŸ¯ Shared model architecture with target network
- ğŸ” Epsilon-greedy exploration with annealing
- ğŸ“‰ Learning rate annealing
- ğŸ“Š Wandb integration for experiment tracking

## ğŸ—ï¸ Project Structure
```
distributed_rl_algos/
â”œâ”€â”€ algorithms/           # Algorithm implementations
â”‚   â””â”€â”€ adqn.py          # Asynchronous DQN implementation
â”œâ”€â”€ common/              # Shared utilities
â”‚   â”œâ”€â”€ network_factory.py
â”‚   â””â”€â”€ utils.py
â””â”€â”€ config/             # Configuration files
    â””â”€â”€ adqn.yaml       # ADQN hyperparameters
```

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/distributed_rl_algos.git
cd distributed_rl_algos
```

2. Install dependencies with Poetry:
```bash
poetry install
poetry shell
```

## ğŸ“‹ Requirements

- Python 3.8+
- PyTorch
- Gymnasium
- Weights & Biases
- Poetry
- Hydra

## ğŸš¦ Quick Start

Run the algorithm with default configurations:

```bash
python examples/train.py algorithm=adqn
```

### Configuration Options

- `num_workers`: Number of parallel workers
- `network.architecture`: Neural network architecture
- `training.lr`: Learning rate
- `training.epsilon`: Exploration parameters
- `training.duration`: Training duration

## ğŸ’» Development

```bash
# Format code
poetry run black .
poetry run isort .

# Run linting
poetry run pylint distributed_rl_algos

# Run tests
poetry run pytest
```

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“š Citation

If you use this code in your research, please cite:

```bibtex
@misc{distributed_rl_algos,
  author = {Your Name},
  title = {Distributed Reinforcement Learning Algorithms},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/yourusername/distributed_rl_algos}
}
```

## ğŸ™ Acknowledgments

- The A3C-DQN implementation is based on the work by Mnih et al.
- Thanks to all contributors who have helped improve this project